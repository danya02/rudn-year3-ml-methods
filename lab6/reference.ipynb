{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bbe095",
   "metadata": {
    "id": "a9bbe095"
   },
   "source": [
    "# Методы машинного обучения – Контрольная работа №6\n",
    "\n",
    "# Рекуррентные нейронные сети RNN\n",
    "\n",
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27adad2",
   "metadata": {
    "id": "e27adad2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6eda2",
   "metadata": {
    "id": "a0a6eda2"
   },
   "source": [
    "## Задача аппроксимации синусоиды при помощи сети MLP\n",
    "\n",
    "В нейронных сетях прямого распространения (многослойных перцептронах, сетях MLP) поток данных движется только в одном направлении, а именно от входного слоя к выходному через скрытые слои."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc0dfc",
   "metadata": {
    "id": "3edc0dfc"
   },
   "source": [
    "Рассмотрим сеть прямого распространения (сеть MLP) с одним скрытым слоем, использующую нелинейную функцию активации, чтобы распознать нелинейную зависимость, задаваемую синусоидой. \n",
    "\n",
    "Будем использовать сеть MLP с одним входным нейроном, десятью скрытыми нейронами и одним выходным нейроном. Скрытые нейроны используют функцию активации гиперболический тангенс ($\\tanh$), тогда как выходной слой использует тождественную функцию активации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23686256",
   "metadata": {
    "id": "23686256"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=(1,), activation='tanh', name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e343e90",
   "metadata": {
    "id": "7e343e90"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf4c09",
   "metadata": {
    "id": "2cbf4c09"
   },
   "source": [
    "При обучении нейронной сети будем использовать оптимизатор `rmsprop` (применяется по умолчанию). В качестве функции ошибок (потерь) будем использовать среднеквадратичную ошибку MSE (mean squared error), а для оценки качества модели – среднюю абсолютную ошибку MAE (mean absolute error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5dafb",
   "metadata": {
    "id": "a9e5dafb"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", # по умолчанию\n",
    "              loss=\"mse\",\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0118d39",
   "metadata": {
    "id": "d0118d39"
   },
   "source": [
    "Обучающие данные содержат $50$ точек $x_{i}$, выбранных случайным образом в диапазоне $\\left[-10,\\,10\\right]$, где $y_{i}=\\sin\\left(x_{i}\\right)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38756f5",
   "metadata": {
    "id": "d38756f5"
   },
   "outputs": [],
   "source": [
    "x_train = 20 * np.random.random(50) - 10\n",
    "y_train = np.sin(x_train)\n",
    "\n",
    "x_plot = np.linspace(-10,10,101)\n",
    "y_plot = np.sin(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9bcbf",
   "metadata": {
    "id": "56c9bcbf"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_plot, y_plot, c='b')\n",
    "plt.scatter(x_train, y_train, s=100, c='r', marker='*');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374dd1b",
   "metadata": {
    "id": "4374dd1b"
   },
   "source": [
    "Будем обучать нейронную сеть на сгенерированных 50 точках, увеличивая количество эпох обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29d182",
   "metadata": {
    "id": "5e29d182"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e24f8e",
   "metadata": {
    "id": "38e24f8e"
   },
   "source": [
    "Оценим качество полученной модели на множестве равноотстоящих точек из отрезка $[-10,10]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd14878",
   "metadata": {
    "id": "bdd14878"
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(-10,10,1001)\n",
    "y_pred = model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1553b68",
   "metadata": {
    "id": "e1553b68"
   },
   "source": [
    "Для визуализации прогноза модели будем использовать функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c78e4",
   "metadata": {
    "id": "7d3c78e4"
   },
   "outputs": [],
   "source": [
    "def show_sin():\n",
    "    print('MSE: {:.3f}, MAE:{:.3f}'.format(*model.evaluate(x_plot, y_plot, verbose=0)))\n",
    "\n",
    "    plt.plot(x_plot, y_plot, c='b')\n",
    "    plt.scatter(x_train, y_train, s=100, c='r', marker='*')\n",
    "    plt.plot(x_pred, y_pred, c='g', lw=3, alpha=0.5);\n",
    "    \n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6f508",
   "metadata": {
    "id": "79b6f508"
   },
   "source": [
    "Увеличим количество эпох обучения до десяти тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619dcbc",
   "metadata": {
    "id": "f619dcbc"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, initial_epoch=1000, epochs=10000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c151cc8",
   "metadata": {
    "id": "3c151cc8"
   },
   "source": [
    "До двацати тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c19113",
   "metadata": {
    "id": "80c19113"
   },
   "outputs": [],
   "source": [
    "%time model.fit(x_train, y_train, initial_epoch=10000, epochs=20000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba2e65",
   "metadata": {
    "id": "82ba2e65"
   },
   "source": [
    "И, наконец, до тридцати тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec5307",
   "metadata": {
    "id": "a6ec5307"
   },
   "outputs": [],
   "source": [
    "%time model.fit(x_train, y_train, initial_epoch=20000, epochs=30000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0a60b",
   "metadata": {
    "id": "85b0a60b"
   },
   "source": [
    "Рисунок свидетельствует о хорошем качестве аппроксимации синусоиды нейронной сетью.\n",
    "\n",
    "Однако выполним прогноз для значений из расширенного диапазона $[-20,20]$ и нарисуем кривые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b33be8",
   "metadata": {
    "id": "d6b33be8"
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(-20,20,1001)\n",
    "y_pred = model.predict(x_pred)\n",
    "\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc682bcf",
   "metadata": {
    "id": "fc682bcf"
   },
   "source": [
    "Таким образом, фактически нейронная сеть прямого распространения только аппроксимировала синусоиду на интервале $[-10,10]$ и не выявила периодичность аппроксимируемой функции. \n",
    "\n",
    "## Задача прогнозирования поведения синусоиды при помощи сети MLP\n",
    "\n",
    "Рассмотрим теперь задачу прогнозирования значений синусоиды.\n",
    "\n",
    "Будем рассматривать в качестве исходного датасета набор значений синусоиды на интервале от $[-10,10]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053e4d3",
   "metadata": {
    "id": "d053e4d3"
   },
   "outputs": [],
   "source": [
    "ds_data = np.sin(np.linspace(-10,10,1001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "niNRxIVx_CCt",
   "metadata": {
    "id": "niNRxIVx_CCt"
   },
   "source": [
    "Обучающая выборка составляет 80% всех данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550dcf5",
   "metadata": {
    "id": "3550dcf5"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(ds_data) * 0.8)\n",
    "test_size = len(ds_data) - train_size\n",
    "ds_train, ds_test = ds_data[:train_size], ds_data[train_size:]\n",
    "ds_train.shape, ds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iRV2S2Cc_Mdp",
   "metadata": {
    "id": "iRV2S2Cc_Mdp"
   },
   "source": [
    "Конвертируем исходный набор в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c663775",
   "metadata": {
    "id": "5c663775"
   },
   "outputs": [],
   "source": [
    "def create_ds(ds, look_back=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(ds)-look_back-1):\n",
    "    a = ds[i:(i+look_back)]\n",
    "    dataX.append(a)\n",
    "    dataY.append(ds[i + look_back])\n",
    "  return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-hgdEdiy_ZhJ",
   "metadata": {
    "id": "-hgdEdiy_ZhJ"
   },
   "source": [
    "Будем делать прогноз на основе 10 предыдущих значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c5d33",
   "metadata": {
    "id": "432c5d33"
   },
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_ds(ds_train, look_back=look_back)\n",
    "testX, testY = create_ds(ds_test, look_back=look_back)\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MRj8k9Lo_jGo",
   "metadata": {
    "id": "MRj8k9Lo_jGo"
   },
   "source": [
    "Изменим форму обучающего и тестового наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e58d60",
   "metadata": {
    "id": "02e58d60"
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "trainX.shape, testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LTU3F0pA_tG8",
   "metadata": {
    "id": "LTU3F0pA_tG8"
   },
   "source": [
    "Создадим сеть MLP с одним скрытым слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a647dc",
   "metadata": {
    "id": "09a647dc"
   },
   "outputs": [],
   "source": [
    "model_mlp = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=(1,look_back), activation='tanh', name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de0567",
   "metadata": {
    "id": "f9de0567"
   },
   "outputs": [],
   "source": [
    "model_mlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_mlp.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsXSd9OK_2cj",
   "metadata": {
    "id": "VsXSd9OK_2cj"
   },
   "source": [
    "Выполним прогноз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fab275",
   "metadata": {
    "id": "a7fab275"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_mlp.predict(trainX)\n",
    "testPredict = model_mlp.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CuVJzyyc_5eb",
   "metadata": {
    "id": "CuVJzyyc_5eb"
   },
   "source": [
    "Используем для оценки качества показатель RMSE, вычисляемый через MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R9VhhVGyCNMl",
   "metadata": {
    "id": "R9VhhVGyCNMl"
   },
   "outputs": [],
   "source": [
    "def my_mse(y_test, y_predict):\n",
    "    return np.sum((y_predict - y_test)**2) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e8c75",
   "metadata": {
    "id": "ac7e8c75"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsHq2W6tAIiW",
   "metadata": {
    "id": "VsHq2W6tAIiW"
   },
   "source": [
    "Для корректной визуализации данных нужно сдвинуть данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c12386",
   "metadata": {
    "id": "a9c12386"
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(ds_data)\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict) + look_back] = trainPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dd356",
   "metadata": {
    "id": "261dd356"
   },
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(ds_data)\n",
    "testPredictPlot[:,] = np.nan\n",
    "testPredictPlot[len(trainPredict) + (look_back * 2) + 1:len(ds_data) - 1] = testPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259461c4",
   "metadata": {
    "id": "259461c4"
   },
   "outputs": [],
   "source": [
    "plt.plot(ds_data, label='Actual')\n",
    "plt.plot(trainPredictPlot.reshape(-1), label='Training')\n",
    "plt.plot(testPredictPlot.reshape(-1), label='Testing')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d0bcf",
   "metadata": {
    "id": "ee5d0bcf"
   },
   "source": [
    "### Решение проблемы исчезающих градиентов\n",
    "\n",
    "#### Инициализация весов\n",
    "\n",
    "Для управления инициализацией весов нужно указать при создании слоя параметр `kernel_initializer`, например, так:\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"relu\", kernel_initializer=\"he_normal\")`\n",
    "\n",
    "или\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"relu\", kernel_initializer=\"he_uniform\")`\n",
    "\n",
    "или\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"sigmoid\", kernel_initializer=keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xy4Xw1alFImF",
   "metadata": {
    "id": "xy4Xw1alFImF"
   },
   "source": [
    "#### Использование функций активации без насыщения\n",
    "\n",
    "Например, можно использовать функцию активации `SELU` (Scaled Exponential Linear Unit) с инициализацией весов `lecun_normal` так:\n",
    "\n",
    "`model.add(tf.keras.layers.Dense(10, kernel_initializer='lecun_normal',\n",
    "                                 activation='selu'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ekV45kg8FLiV",
   "metadata": {
    "id": "ekV45kg8FLiV"
   },
   "source": [
    "#### Пакетная нормализация (Batch Normalization)\n",
    "\n",
    "Слой пакетной нормализации может быть добавлен в модель так:\n",
    "\n",
    "`model.add(tf.keras.layers.BatchNormalization())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-jiugeceFXXT",
   "metadata": {
    "id": "-jiugeceFXXT"
   },
   "source": [
    "#### Обрезка градиентов (Gradient Clipping)\n",
    "\n",
    "При обрезке градентов при задании оптимизатора в методе `compile()` указывается параметр `clipvalue` или `clipnorm`, например: \n",
    "\n",
    "`model.compile(optimizer=optimizer = keras.optimizers.SGD(clipvalue = 1.0),\n",
    "              loss=\"mse\", metrics=[\"mae\"])`   \n",
    "\n",
    "или\n",
    "\n",
    "`model.compile(optimizer=optimizer = keras.optimizers.SGD(clipnorm = 1.0),\n",
    "              loss=\"mse\", metrics=[\"mae\"])` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzMlqRQ8AWe1",
   "metadata": {
    "id": "wzMlqRQ8AWe1"
   },
   "source": [
    "Попробуем решить задачу прогноза значений синусоиды при помощи глубокой сети MLP с применением пакетной нормализации, функций активации без насыщения и альтернативной инициализации весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7acc6",
   "metadata": {
    "id": "9cb7acc6"
   },
   "outputs": [],
   "source": [
    "model_dmlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(1,look_back), \n",
    "                          kernel_initializer='lecun_normal', activation='selu'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer='lecun_normal', activation='selu'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_dmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a3fd7",
   "metadata": {
    "id": "001a3fd7"
   },
   "outputs": [],
   "source": [
    "model_dmlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_dmlp.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7JMB4NJHF3Xe",
   "metadata": {
    "id": "7JMB4NJHF3Xe"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_dmlp.predict(trainX)\n",
    "testPredict = model_dmlp.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZJKwaWSJF_qj",
   "metadata": {
    "id": "ZJKwaWSJF_qj"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joiDaqT6GVm8",
   "metadata": {
    "id": "joiDaqT6GVm8"
   },
   "source": [
    "## Рекуррентная нейронная сеть RNN\n",
    "\n",
    "__Рекуррентные нейронные сети__ (Recurrent Neural Networks, __RNN__) включают обратную связь от одного уровня к другому, и их обычно можно обучить, развертывая рекуррентные соединения, в результате чего получаются глубокие сети, параметры которых можно обучить с помощью алгоритма обратного распространения ошибки. \n",
    "\n",
    "Если многослойные персептроны представляют собой сети прямого распространения, в которых информация движется только в одном направлении, а именно от входного слоя к выходному через скрытые слои, то рекуррентные нейронные сети (RNN) содержат петли (циклы) обратной связи между двумя (или более) слоями, что делает их идеальными для обучения на основе входных данных в форме последовательностей. \n",
    "\n",
    "Задача сети RNN состоит в том, чтобы аппроксимировать функцию, которая предсказывает целевую выходную последовательность $\\mathcal{Y}$ по заданной входной последовательности $\\mathcal{X}$. То есть прогнозируемые выходные данные (результат) $\\mathbf{o}_{t}$ для входных данных $\\mathbf{x}_{t}$ должны быть аналогичны или близки к целевому отклику $\\mathbf{y}_{t}$ для каждого момента времени $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabfac4",
   "metadata": {
    "id": "4dabfac4"
   },
   "outputs": [],
   "source": [
    "model_rnn = tf.keras.Sequential([\n",
    "  tf.keras.layers.SimpleRNN(10, input_shape=(1,look_back), name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea77e3",
   "metadata": {
    "id": "08ea77e3"
   },
   "outputs": [],
   "source": [
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_rnn.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304173bb",
   "metadata": {
    "id": "304173bb"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_rnn.predict(trainX)\n",
    "testPredict = model_rnn.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031b094",
   "metadata": {
    "id": "7031b094"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76cad7",
   "metadata": {
    "id": "ef76cad7"
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(ds_data)\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict) + look_back] = trainPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738ecd3",
   "metadata": {
    "id": "5738ecd3"
   },
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(ds_data)\n",
    "testPredictPlot[:,] = np.nan\n",
    "testPredictPlot[len(trainPredict) + (look_back * 2) + 1:len(ds_data) - 1] = testPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8f7ef",
   "metadata": {
    "id": "57d8f7ef"
   },
   "outputs": [],
   "source": [
    "plt.plot(ds_data, marker='o', c='y', lw=5, label='Actual')\n",
    "plt.plot(trainPredictPlot.reshape(-1), c='b', label='Training')\n",
    "plt.plot(testPredictPlot.reshape(-1), c='r', label='Testing')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f131a45",
   "metadata": {
    "id": "8f131a45"
   },
   "source": [
    "Рассмотрим теперь более общую задачу прогнозирования значений временного ряда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb3a1e",
   "metadata": {
    "id": "62eb3a1e"
   },
   "source": [
    "## Прогнозирование значений временного ряда\n",
    "\n",
    "_Временной ряд_ представляет собой любые данные, полученные путем измерений через равные промежутки времени, например, дневная цена акции, почасовое потребление электроэнергии в городе или еженедельные продажи в магазине. Временные ряды встречаются в различных сферах  деятельности от изучения природных явлений (сейсмическую активность, эволюция популяций рыб в реке, погода в определенном месте и пр.) до экономики (посетители веб-сайта, ВВП страны, операции с кредитными картами и т.п.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce266e",
   "metadata": {
    "id": "51ce266e"
   },
   "source": [
    "Наиболее распространенной задачей, связанной с временными рядами, является прогнозирование – предсказание дальнейшей динамики временного ряда. Необходимо прогнозировать потребление электроэнергии, чтобы предвидеть спрос; прогнозировать доход на несколько месяцев вперед, чтобы планировать бюджет; прогнозировать погоду на несколько дней вперед, чтобы планировать расписание."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97916d",
   "metadata": {
    "id": "5a97916d"
   },
   "source": [
    "Рассмотрим задачу прогнозирования температуры воздуха через 24 часа, учитывая временной ряд часовых измерений таких величин, как атмосферное давление и влажность. \n",
    "\n",
    "Этот набор данных был записан на метеостанции в Институте биогеохимии им. Макса Планка в Йене, Германия. В этом наборе 14 различных величин (таких как температура, давление, влажность, направление ветра и т.д.) записанных с интервалом 10 минут за несколько лет. Набор можно загрузить по адресу `https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df800987",
   "metadata": {
    "id": "df800987"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "fname = os.path.join(\"DATA/jena_climate_2009_2016.csv\")\n",
    "\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "\n",
    "lines = data.split(\"\\n\")      # list with headers and text lines with date and data\n",
    "header = lines[0].split(\",\")  # list of column names\n",
    "lines = lines[1:]             # list of text lines with date and data\n",
    "print('Атрибуты набора данных:', header)\n",
    "print('\\nКоличество записей:', len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d28e4",
   "metadata": {
    "id": "ff1d28e4"
   },
   "source": [
    "Всего в наборе 420451 строк данных (записей), содержащих метку с датой/временем и 14 погодных показателей. Исключим столбец с датой/временем и загрузим температурные показатели в массив `temperature` и все показатели (включая температуру) в массив `raw_data`. \n",
    "\n",
    "Нарисуем также график температуры (в градусах Цельсия) в зависимости от времени (номера записи):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9aefa",
   "metadata": {
    "id": "56c9aefa"
   },
   "outputs": [],
   "source": [
    "temperature = np.zeros((len(lines),))\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]] # list of values w/o date\n",
    "    temperature[i] = values[1]                       # temperature only\n",
    "    raw_data[i, :] = values[:]                       # all values\n",
    "    \n",
    "plt.plot(range(len(temperature)), temperature);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76407663",
   "metadata": {
    "id": "76407663"
   },
   "source": [
    "На графике прослеживаются сезонные изменения температуры (за 8 лет). Однако температура также изменяется в зависимости от времени суток. Это видно на температурном графике за 10 дней (т.к. данные измеряются каждые 10 минут, ежедневно сохраняется $24 * 6 = 144$ записи)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf1dc9",
   "metadata": {
    "id": "8adf1dc9"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1440), temperature[:1440]); # 1440 = 10 x 24 x 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8bc40",
   "metadata": {
    "id": "87c8bc40"
   },
   "source": [
    "Будем использовать первые 50% данных в наборе для обучения, следующие 25% для валидации и последние 25% для тестирования. Вычислим количество записей в обучающей, валидационной и тестовой выборках: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7574838",
   "metadata": {
    "id": "e7574838"
   },
   "outputs": [],
   "source": [
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09ea11",
   "metadata": {
    "id": "5c09ea11"
   },
   "source": [
    "Нормализуем каждый столбец в массиве `raw_data` по данным обучающей выборки (по первым `num_train_samples` записям), чтобы все столбцы принимали небольшие значения в одинаковом масштабе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8b1c2",
   "metadata": {
    "id": "51a8b1c2"
   },
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std # whole raw_data normalized w.r.t. first num_train_samples rows\n",
    "\n",
    "mean.shape, std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf425602",
   "metadata": {
    "id": "cf425602"
   },
   "source": [
    "Теперь создадим набор (объект) с данными за последние пять дней вместе с целевым показателем температуры через 24 часа. Для этого используем встроенную в модуль Keras функцию `timeseries_dataset_from_array()`. Чтобы проиллюстрировать работу этой функции, рассмотрим следующий простой пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8be34",
   "metadata": {
    "id": "0eb8be34"
   },
   "outputs": [],
   "source": [
    "int_sequence = np.arange(10)   # [0,1,2,3,4,5,6,7,8,9]\n",
    "dummy_dataset = tf.keras.utils.timeseries_dataset_from_array( # объект BatchDataset\n",
    "    data=int_sequence[:-3],    # [0,1,2,3,4,5,6]\n",
    "    targets=int_sequence[3:],  # [3,4,5,6,7,8,9]\n",
    "    sequence_length=3,         # длина последовательности\n",
    "    batch_size=2,              # размер батча (пакета)\n",
    ")\n",
    "\n",
    "for inputs, targets in dummy_dataset: # tf.Tensor objects\n",
    "    for i in range(inputs.shape[0]):\n",
    "        print([int(x) for x in inputs[i]], int(targets[i]))\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25fc44",
   "metadata": {
    "id": "4a25fc44"
   },
   "source": [
    "Используем `timeseries_dataset_from_array()` для создания трех наборов данных (объектов `BatchDataset`) – для обучения, для валидации и для тестирования со следующими значениями параметров:\n",
    "\n",
    "* `sample_rate = 6` — наблюдения будут производиться в одной точке данных в час - будем хранить только одну точку данных из 6;\n",
    "* `sequence_length=120` — наблюдения будут браться за 5 дней (120 часов);\n",
    "* `delay=sampling_rate*(sequence_length+24-1)` — целью для входной последовательности будет температура через 24 часа после окончания последовательности;\n",
    "\n",
    "При создании набора обучающих данных передадим в функцию аргементы `start_index = 0` и `end_index = num_train_samples`, чтобы использовать только первые 50% данных. Для набора данных валидации передадим в функцию `start_index = num_train_samples` и `end_index = num_train_samples + num_val_samples`, чтобы использовать следующие 25% данных. Наконец, для тестового набора данных передадим `start_index=num_train_samples+num_val_samples`, чтобы использовать оставшиеся данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1001f07",
   "metadata": {
    "id": "d1001f07"
   },
   "outputs": [],
   "source": [
    "sampling_rate = 6\n",
    "sequence_length = 120\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples)\n",
    "\n",
    "val_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f4359",
   "metadata": {
    "id": "299f4359"
   },
   "source": [
    "Каждый набор данных содержит кортежи `(samples, targets)`, где `samples` представляет собой пакет из 256 записей, каждая из которых содержит 120 последовательных часовых записей данных, а `targets` представляет собой соответствующий массив из 256 температур. Обратите внимание, что записи перемешиваются случайным образом, поэтому две соседние последовательности в пакете (например, `samples[0]` и `samples[1]`) не обязательно близки по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b33ac",
   "metadata": {
    "id": "483b33ac"
   },
   "outputs": [],
   "source": [
    "for samples, targets in train_dataset: # shapes in first data batch\n",
    "    print(\"Форма признаков:\", samples.shape)\n",
    "    print(\"Форма откликов:\", targets.shape)\n",
    "    break # first batch only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a4656",
   "metadata": {
    "id": "803a4656"
   },
   "source": [
    "Оценим ошибку для следующего элементарного подхода к прогнозированию температуры, когда в качестве прогнозного значения температуры через 24 часа принимается текущее значение температуры. В качестве показателя качества модели прогнозирования будем использовать метрику MAE (mean absolute error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a46fc7",
   "metadata": {
    "id": "58a46fc7"
   },
   "outputs": [],
   "source": [
    "def evaluate_naive_method(dataset):\n",
    "    total_abs_err = 0.\n",
    "    samples_seen = 0\n",
    "    for samples, targets in dataset:\n",
    "        preds = samples[:, -1, 1] * std[1] + mean[1] # std and mean of temperature\n",
    "        total_abs_err += np.sum(np.abs(preds - targets))\n",
    "        samples_seen += samples.shape[0]\n",
    "    return total_abs_err / samples_seen\n",
    "\n",
    "print(f\"MAE на валидационном наборе: {evaluate_naive_method(val_dataset):.2f}\")\n",
    "print(f\"MAE на тестовом наборе: {evaluate_naive_method(test_dataset):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb50bb2-f8e7-4e0f-a741-86322b62692d",
   "metadata": {},
   "source": [
    "## Функциональный интерфейс Keras\n",
    "\n",
    "В модуле __Keras__ имеется два интерфейса (API) для быстрого построения архитектур нейронных сетей: последовательный интерфейс (Sequential API) и функциональный интерфейс (Functional API). Первый интерфейс позволяет строить только последовательные архитектуры нейронных сетей, в которых выход каждого слоя передается на вход следующего слоя. При помощи функционального интерфейса можно задать нейронную сеть в виде произвольного направленного ациклического графа, что дает намного больше возможностей для построения сложных моделей. В частности, функциональный интерфейс может обрабатывать модели с нелинейной топологией, модели с общими слоями, и модели с несколькими входами или выходами.\n",
    "\n",
    "Воссоздадим при помощи функционального интерфейса глубокую сеть MLP, ранее созданную при помощи последовательного интерфейса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708dc12e-bf0b-4577-81a0-af23ec96a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dmlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb93d2f8-e82b-48ab-a711-d1e0be88ac90",
   "metadata": {},
   "source": [
    "Сначала создаем входные данные нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e3a4a-770b-43ad-8045-fa143c31f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1,look_back))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a91ed-3345-447c-a751-15b470c04a6f",
   "metadata": {},
   "source": [
    "Здесь указывается размерность данных, при этом количество данных всегда опускается. Переменная `inputs` содержит информацию о размерах и типе данных которые будут передаваться в модель: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f896d-bd1c-4a97-9e96-9ab544f09384",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape, inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c4ca9-a88c-477d-b55a-ec8aad73a680",
   "metadata": {},
   "source": [
    "Создаем новый слой в графе слоев с `inputs` в качестве входных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeff15c-4f3c-4693-847c-4aad5b443a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(10, kernel_initializer='lecun_normal', activation='selu')(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0b80f-dddd-4d89-b5af-6ca6289573ad",
   "metadata": {},
   "source": [
    "Добавим еще несколько слоев в граф слоев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971aad4-90ca-4180-8f7b-954e30939109",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(10, kernel_initializer='lecun_normal', activation='selu')(x)  \n",
    "x = tf.keras.layers.BatchNormalization()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac44ef-ad16-48ea-8c10-b84a60b10046",
   "metadata": {},
   "source": [
    "Наконец, добавим последний слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006b826-f07c-4a69-9599-bd2765088f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Dense(1, name='OutputLayer')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24561c-b6b0-4bb8-a092-3e5c998423c9",
   "metadata": {},
   "source": [
    "Теперь создаем модель, указав ее входы и выходы в графе слоев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d8b67-956e-40d3-b334-d8e1c838b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dmlp2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_dmlp2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b47ae-8833-4347-8b93-0b4ba62a3c5a",
   "metadata": {},
   "source": [
    "Можем начертить модель в виде графа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81023751-9c95-4fa5-86e2-2c72d864359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_dmlp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facca116-925c-4ade-89d1-1c9b80ab24a6",
   "metadata": {},
   "source": [
    "Можно вывести размерности входа и выхода каждого слоя на построенном графе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5393a-65b8-4451-af84-1134a0ed9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_dmlp2, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f35f3-531d-422b-934d-bbc029d280f5",
   "metadata": {},
   "source": [
    "Обучение, оценка качества и прогноз работают для моделей, построенных с использованием функционального интерфейса, точно так же как и для последовательных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2269a7",
   "metadata": {
    "id": "8e2269a7"
   },
   "source": [
    "## Прогнозирование температуры при помощи сети MLP\n",
    "\n",
    "Рассмотрим модель нейронной сети прямого распространения (сети MLP), которая начинается с выравнивания данных, а затем проходит через два плотных слоя. Функция активации на последнем плотном слое (выходном слое)  отсутствует, что типично для задачи регрессии. В качестве потерь используется среднеквадратичную ошибку (MSE), так как, в отличие от MAE, функция MSE гладкая около нуля, что является полезным свойством для градиентного спуска. Показатель MAE будет отслеживаться в качестве метрики модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443668",
   "metadata": {
    "id": "f6443668"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=5,\n",
    "                    validation_data=val_dataset,\n",
    "                   ) \n",
    "\n",
    "print(f\"MAE на тестовом наборе: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uGzV7zqGurh6",
   "metadata": {
    "id": "uGzV7zqGurh6"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c42c5",
   "metadata": {
    "id": "f63c42c5"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"MAE на обучающей выборке\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"MAE на валидационной выборке\")\n",
    "plt.title(\"Ошибка MAE на обучающей и валидационной выборках\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd29158",
   "metadata": {
    "id": "2fd29158"
   },
   "source": [
    "Результаты обучение нейронной сети свидетельствуют, что ошибка построенной модели на валидационном наборе (а также на тестовом наборе) превышает аналогичные ошибки для наивной модели прогнозирования температуры. Поэтому использование нейронной сети прямого распространения не позволяет получить модель прогнозирования приемлемого качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60e6c4",
   "metadata": {
    "id": "bb60e6c4"
   },
   "source": [
    "## Прогнозирование температуры при помощи сети RNN\n",
    "\n",
    "Попробуем теперь построить модель прогнозирования температуры на основе простой сети RNN с одним скрытым слоем c 16 нейронами и выходным слоем из одного нейрона:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7c73e",
   "metadata": {
    "id": "55f7c73e"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = tf.keras.layers.LSTM(16)(inputs) \n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=5,\n",
    "                    validation_data=val_dataset,\n",
    "                   ) \n",
    "\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422a917",
   "metadata": {
    "id": "9422a917"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs[1:], loss[1:], \"bo\", label=\"MAE на обучающей выборке\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"MAE на валидационной выборке\")\n",
    "plt.title(\"Ошибка MAE на обучающей и валидационной выборках\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353da14",
   "metadata": {
    "id": "d353da14"
   },
   "source": [
    "Таким образом, применение сети RNN позволило улучшить показатели качества модели прогнозирования и получить модель с лучшим качеством прогноза, чем наивная модель прогнозирования. \n",
    "\n",
    "Почему получилось улучшить показатели качества модели по сравнению с моделью на основе сети MLP? Сети прямого распространения (сети MLP) не имеют памяти. Каждый элемент входных данных обрабатывается независимо, при этом, чтобы обработать последовательность или временной ряд точек данных, нужно отправить всю последовательность данных нейронной сети сразу, превратив ее в единую точку данных. \n",
    "\n",
    "Рекуррентная нейронная сеть (RNN) обрабатывает последовательность данных, перебирая элементы последовательности и поддерживая внутреннее состояние, содержащее информацию относительно того, что сеть видела до сих пор. По сути, сеть RNN — это тип нейронной сети с внутренним циклом.\n",
    "\n",
    "Состояние сети RNN сбрасывается между обработкой двух разных независимых последовательностей (например, двух записей в пакете), так что по-прежнему  последовательность считается одной точкой данных. Но эта точка данных больше не обрабатывается за один шаг – скорее, сеть внутренне зацикливается на элементах последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c20492-5a9c-433b-afc7-94207dd774c5",
   "metadata": {},
   "source": [
    "### Разреженная категориальная перекрестная энтропия\n",
    "\n",
    "При использовании разреженной категориальной перекрестной энтропии (sparse categorical crossentropy) входными данными должны быть индексы классов, поэтому при использовании в качестве функции потерь функции `tf.keras.losses.SparseCategoricalCrossentropy` делается следующее:\n",
    "\n",
    "* метки данных не перекодируются в однократные векторы (one-hot encoding), но перекодируются в скалярные индексы классов 0, 1, 2 и т.д.\n",
    "* в выходном слое (как и в случае категориальной кросс-энтропии) используется количество нейронов, равное числу классов\n",
    "* в выходном слое используется функция активации `softmax`\n",
    "\n",
    "Рассмотрим построение рекуррентной нейронной сети для классификации изображений с использованием  разреженной категориальной перекрестной энтропии. Загрузим набор с рукописными цифрами `MNIST`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08192b64-2275-4075-90f8-8eb25b94df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1626cc-c703-4c11-ac3f-4bcb13b05c81",
   "metadata": {},
   "source": [
    "Вот пример цифры из этого набора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3023404-0b55-4dd4-9432-a0e2a6914b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sample_label = x_train[0], y_train[0]\n",
    "plt.imshow(sample)\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78c5d4-016d-4e20-a9c4-c3780c83bbcc",
   "metadata": {},
   "source": [
    "Каждый пакет изображений из набора MNIST будет иметь форму (batch_size, 28, 28). Каждая входная последовательность будет иметь размеры (28, 28), т.е. второе измерение трактуется как временная переменная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445f528-34e4-4a5b-9165-50f0c6bd5723",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_dim = 28\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad45b4bd-bfd9-41bf-9e2e-d11b97037324",
   "metadata": {},
   "source": [
    "Создаем модель со слоем LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3ee9d-e778-4bd4-a31c-5e8ab29d5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.LSTM(units, input_shape=(None, input_dim)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(output_size, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870b673-0241-4f0c-9c3c-e81d3cd78627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0109472-4cea-46a8-9490-5b7fff915c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_LSTM.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee2940-34ae-4ac0-8ea0-5a2184c27c51",
   "metadata": {},
   "source": [
    "Построим прогноз для первого элемента обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7f450-5e67-431c-855f-eb9eaa97ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.predict(x_train[0].reshape(-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e1050-f5c2-4082-9776-94a175e7ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model_LSTM.predict(x_train[0].reshape(-1,28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb55133-f2f9-43b7-88f3-f7232d6f99fd",
   "metadata": {},
   "source": [
    "### Ранняя остановка обучения\n",
    "\n",
    "Для предотвращения переобучения нейронной сети можно использовать мощный инструмент коллбэков (callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a9ef0-badc-415f-baf1-bfab138b2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_LSTM.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=50, callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TD5MSjDcheYa",
   "metadata": {
    "id": "TD5MSjDcheYa"
   },
   "source": [
    "### Задание на КР №6\n",
    "\n",
    "В соответствии с индивидуальным заданием, указанным в записной книжке команды, сделайте необходимые расчеты и постройте следующие визуализации:\n",
    "\n",
    "1.\tЗагрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую, и валидационную и тестовую выборки. Если при дальнейшей работе с данными возникнет нехватка вычислительных ресурсов, то разрешение изображений можно уменьшить. \r\n",
    "2.\tОставьте в наборе изображения, указанных в индивидуальном задании, и визуализируйте несколько изображений.\r\n",
    "3.\tПостройте нейронные сети MLP, CNN и RNN для задачи многоклассовой классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании), используя функцию потерь, указанную в индивидуальном задании. Подберите такие параметры обучения, как оптимизатор, начальная скорость обучения самостоятельно, обеспечивая обучение нейронных сетей. Останавливайте обучение нейронных сетей в случае роста потерь на валидационной выборке на нескольких эпохах обучения подряд. Для каждой нейронной сети выведите количество потребовавшихся эпох обучения. \r\n",
    "4.\tОцените качество многоклассовой классификации нейронными сетями MLP, CNN и RNN на тестовой выборке при помощи показателя качества, указанного в индивидуальном задании, и выведите архитектуру нейронной сети с лучшим качеством. \r\n",
    "5.\tВизуализируйте кривые обучения трех построенных моделей для показателя потерь на одном рисунке в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. Используйте для визуализации относительные потери (потери, деленные на начальную потери на первой эпохе).\r\n",
    "6.\tВизуализируйте кривые обучения трех построенных моделей для показателя доли верных ответов на валидационной выборке на одном рисунке в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\r\n",
    "7.\tДля каждого из классов определите два изображения в тестовой выборке, имеющее минимальную и максимальную вероятности классификации в правильный класс, и визуализируйте эти изображения.\r\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kyUEqC2Zh1Uf",
   "metadata": {
    "id": "kyUEqC2Zh1Uf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab5_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
